\section{Introduction}
This serves as a brief starting point for understanding how the Curry-Howard correspondence appears in Lean, 
as well as being an introduction to the language itslef. 
Lean is both a \textbf{functional programming language} and a \textbf{theorem prover}.
We'll focus primarily on its role as a theorem prover. 
But what does this mean, and how can that be achieved?

A programming language defines a \textbf{set of rules, semantics, and syntax} for writing programs. 
To achieve a goal, a programmer must write a program that meets given specifications. 
There are two primary approaches: \textbf{program derivation} and \textbf{program verification} 
( \cite{nordstrom1990programming} Section 1.1).
In \textbf{program verification}, the programmer first writes a program and then proves it meets 
the specifications. This approach checks for errors at \textbf{runtime} when the code executes.
In \textbf{program derivation}, the programmer writes a proof that a program with certain properties exists, 
then extracts a program from that proof. This approach enables specification 
checking during \textbf{compilation}, catching errors before execution.
This distinction corresponds to \textbf{dynamic} versus \textbf{static} \textbf{type systems}. 
Most programming languages employ both approaches. For example, C checks operations on \texttt{int} 
at compile time but requires the programmer to ensure correctness with \texttt{void*} at run time.
Lean emphasizes program derivation.
Its type system is highly advanced and flexible, allowing the expression and verification 
of a wide range of mathematical statements, and this is what makes Lean a powerful \textbf{theorem prover}. 
Lean's type system is based on \textbf{Type Theory}, a branch of marthematics and logic tahta aims to provide a 
foundation for all mathematics and wich is a programming language itself.

It's important to note that Type Theory is not a single, unified theory, but rather a family of 
related theories with various extensions and ongoing developments and rich hiostorical ramifications. 
Creating a language like Lean require
careful consideration of which rules and features to include.
We shall give a brief overview of the historical development of type theory, and an a introduction on 
what comes next.

(From \cite{carneiro2019typetheorylean})
Type theory emerged as a fundamental response to Bertrand Russell's paradox. 
Considers the set $S = \{x \mid x \notin x\}$ 
(the set of all sets that do not contain themselves). This is a paradoxical construction, 
leading to the contradiction $S \in S \iff S \notin S$. 
Ernst Zermelo and Fraenkel addressed the contradiction by introducing Zermelo-Fraenkel set theory (ZFC), 
which became the standard axiomatization in modern mathematics. 
ZFC provides an untyped but stratified view of the mathematical universe, 
maintaining classical logical principles while avoiding paradoxes through careful axiomatization.
Russell chose a fundamentally different path. He recognized expressions 
like $A(A)$ or $x \in x$ as ill-typed, introducing his theory of types.
Hs's first systematic response was \textbf{Ramified Type Theory}, wich turned out to be problematic.
In the 1930s, Alonzo Church developed \textbf{Lambda Calculus} as a foundation for mathematics, 
initially pursuing a type-free approach. However, Church's original untyped system suffered from 
inconsistencies. To address these issues, 
Church introduced the \textbf{Simply Typed Lambda Calculus} in 1940 (\cite{church1940formulation}).  
This system is a version of \textbf{Simple Type Theory}, a framework able to replace 
set-theory and propositional logic.
Lambda calculus influenced the development of many programming languages as being a foundation for
functional programming.
Per Martin-L\"{o}f revolutionized type theory in the 1970s by introducing 
\textbf{dependent types} that can depend on values of other types.
Think for instance of a of vectors of length $n$ or a sequnce of $n$ elements.
\textbf{Dependent Type Theory} extends the expressive power of type systems 
by allowing the representation of quantifiers, 
providing a framework capable of replacing set theory and predicate logic.
Dependent Type Theory is a derivation of \textbf{Martin-L\"{o}f Type Theory} 
(also known as \textbf{Intuitionistic Type Theory}).
Martin-L\"{o}f's system embraced constructive principles, requiring that the existence of mathematical 
objects be demonstrated through explicit construction rather than classical proof by contradiction. 
Martin-L\"{o}f Type Theory also introduced \textbf{identity types} to represent equality.
In the 1980s, Thierry Coquand and G\'{e}rard Huet introduced the \textbf{Calculus of Constructions} (CoC), 
synthesizing insights from Martin-L\"{o}f's dependent type theory with higher-order \textbf{polymorphism}. 
The Calculus of Constructions served as the theoretical foundation for the Coq proof assistant, 
one of the most influential interactive theorem provers.
The original CoC was later extended with \textbf{inductive types} to form the 
\textbf{Calculus of Inductive Constructions} (CIC). Inductive types allow for the definition 
of data structures like natural numbers, lists, and trees. 
The Lean theorem prover, developed by Leonardo de Moura and others, is also based on CIC 
but incorporates several important refinements and differences from Coq's implementation. 

A central insight in type theory is the \textbf{Curry-Howard correspondence}, 
which establishes a profound connection between logic and computation. 
Also known as the \textbf{propositions-as-types} principle, this correspondence 
represents one of the most elegant discoveries in the foundations 
of mathematics and computer science.
It serves also well as a good introduction to type theory, and will be used in this discussion.
Nontheless it continuelsy shows new applications and interpretations in modern type theories.
The Curry-Howard correspondence was independently discovered by multiple researchers.
\textbf{Haskell Curry} (1934) first observed the connection between combinatory logic and 
Hilbert-style proof systems.
\textbf{William Alvin Howard} (1969) significantly extended the correspondence to natural deduction 
and the simply typed lambda calculus in his seminal work ``The Formulae-as-Types Notion of Construction.'' 
The correspondence was further developed through \textbf{N.G. de Bruijn's AUTOMATH system} (1967), 
which was the first working proof checker and demonstrated the practical viability of mechanical 
proof verification. Amongst its technical innovations are a discussion of the
irrelevance of proofs when working in a classical context, which is one
of the reasons advanced by de Bruijn for the separation between the notions of 
type and prop in the system \cite{thompson1999types}. Lean also adopts this separation .
\textbf{Per Martin-L\"{o}f's type theory} extended the correspondence to
dependent types, allowing for the representation of quantifiers and identity types.
Modern proof assistants like Coq, Lean, Agda, and Isabelle/HOL all leverage 
variants of the Curry-Howard correspondence to enable formal verification of mathematical theorems 
and software correctness properties.

% Throughout this discussion, we will introduce how to read Type Theory notation and explore key concepts 
% including:
% \begin{itemize}
% \item Impredicativity
% \item Decidability
% \item Computability
% \item Derivability
% \item Soundness
% \item Completeness
% \item Intyensionality 
% \item Extensionality
% \end{itemize}

